{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_AJLgPCqYP0",
        "outputId": "2cb60ea4-c86d-4ae0-f9df-38c1113e0ff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 GPU(s) ready with memory growth.\n",
            "Epoch 1/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 72ms/step - accuracy: 0.0338 - loss: 4.5594 - val_accuracy: 0.0126 - val_loss: 9.8946 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.1614 - loss: 3.4827 - val_accuracy: 0.0467 - val_loss: 5.8692 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.2864 - loss: 2.8342 - val_accuracy: 0.2700 - val_loss: 2.9360 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.3864 - loss: 2.3140 - val_accuracy: 0.5540 - val_loss: 1.7165 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.4652 - loss: 1.9488 - val_accuracy: 0.6473 - val_loss: 1.2791 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.5261 - loss: 1.6922 - val_accuracy: 0.7141 - val_loss: 1.0978 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.5720 - loss: 1.5069 - val_accuracy: 0.7407 - val_loss: 0.9360 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.6062 - loss: 1.3436 - val_accuracy: 0.7640 - val_loss: 0.8771 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.6586 - loss: 1.1877 - val_accuracy: 0.7890 - val_loss: 0.7735 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.6832 - loss: 1.0703 - val_accuracy: 0.8042 - val_loss: 0.6850 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.7076 - loss: 0.9695 - val_accuracy: 0.8230 - val_loss: 0.6274 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.7314 - loss: 0.8797 - val_accuracy: 0.8415 - val_loss: 0.5745 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.7590 - loss: 0.8025 - val_accuracy: 0.8574 - val_loss: 0.5236 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.7777 - loss: 0.7363 - val_accuracy: 0.8629 - val_loss: 0.4895 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.7881 - loss: 0.6889 - val_accuracy: 0.8733 - val_loss: 0.4782 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.8157 - loss: 0.6126 - val_accuracy: 0.8804 - val_loss: 0.4533 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.8206 - loss: 0.5736 - val_accuracy: 0.8794 - val_loss: 0.4417 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.8239 - loss: 0.5633 - val_accuracy: 0.8846 - val_loss: 0.4172 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.8357 - loss: 0.5051 - val_accuracy: 0.8833 - val_loss: 0.4116 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.8531 - loss: 0.4597 - val_accuracy: 0.8827 - val_loss: 0.3999 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - accuracy: 0.8616 - loss: 0.4334 - val_accuracy: 0.8930 - val_loss: 0.3789 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.8700 - loss: 0.4104 - val_accuracy: 0.8878 - val_loss: 0.3930 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.8660 - loss: 0.4102 - val_accuracy: 0.8989 - val_loss: 0.3572 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.8777 - loss: 0.3699 - val_accuracy: 0.8940 - val_loss: 0.3831 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.8850 - loss: 0.3465 - val_accuracy: 0.9063 - val_loss: 0.3385 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.9018 - loss: 0.3003 - val_accuracy: 0.9047 - val_loss: 0.3451 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9039 - loss: 0.2868 - val_accuracy: 0.8904 - val_loss: 0.3775 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.9083 - loss: 0.2715 - val_accuracy: 0.8982 - val_loss: 0.3792 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9081 - loss: 0.2731\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.9082 - loss: 0.2731 - val_accuracy: 0.8976 - val_loss: 0.3633 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9169 - loss: 0.2387 - val_accuracy: 0.8947 - val_loss: 0.3766 - learning_rate: 5.0000e-05\n",
            "Epoch 31/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 38ms/step - accuracy: 0.9214 - loss: 0.2299 - val_accuracy: 0.9044 - val_loss: 0.3528 - learning_rate: 5.0000e-05\n",
            "Epoch 32/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.9349 - loss: 0.1990 - val_accuracy: 0.9021 - val_loss: 0.3515 - learning_rate: 5.0000e-05\n",
            "Epoch 33/100\n",
            "\u001b[1m192/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9293 - loss: 0.2022\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.9293 - loss: 0.2021 - val_accuracy: 0.8982 - val_loss: 0.3752 - learning_rate: 5.0000e-05\n",
            "Epoch 34/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 37ms/step - accuracy: 0.9406 - loss: 0.1852 - val_accuracy: 0.9044 - val_loss: 0.3483 - learning_rate: 2.5000e-05\n",
            "Epoch 35/100\n",
            "\u001b[1m193/193\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.9387 - loss: 0.1746 - val_accuracy: 0.9011 - val_loss: 0.3622 - learning_rate: 2.5000e-05\n",
            "Epoch 35: early stopping\n",
            "Restoring model weights from the end of the best epoch: 25.\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9029 - loss: 0.3749\n",
            "\n",
            "Test Accuracy: 90.63%\n",
            "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy       : 90.63%\n",
            "Precision (avg): 0.9086\n",
            "Recall    (avg): 0.9058\n",
            "F1 Score  (avg): 0.9056\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85        46\n",
            "           1       1.00      0.95      0.97        79\n",
            "           2       1.00      0.91      0.95        33\n",
            "           3       0.82      0.78      0.80        51\n",
            "           4       0.95      0.90      0.93        42\n",
            "           5       0.92      0.90      0.91        50\n",
            "           6       1.00      0.76      0.86        42\n",
            "           7       0.90      0.90      0.90        31\n",
            "           8       0.80      0.86      0.83        51\n",
            "           9       1.00      0.90      0.95        41\n",
            "          10       0.85      0.85      0.85        55\n",
            "          11       0.66      0.86      0.75        36\n",
            "          12       0.93      0.91      0.92        43\n",
            "          13       0.89      0.92      0.90        36\n",
            "          14       0.91      0.75      0.82        40\n",
            "          15       0.96      0.98      0.97        47\n",
            "          16       0.85      0.85      0.85        46\n",
            "          17       0.89      0.97      0.93        32\n",
            "          18       0.94      0.88      0.91        52\n",
            "          19       0.95      0.97      0.96        39\n",
            "          20       0.91      0.94      0.93        34\n",
            "          21       0.89      0.97      0.93        32\n",
            "          22       0.92      0.80      0.86        41\n",
            "          23       0.97      0.95      0.96        39\n",
            "          24       1.00      0.86      0.93        44\n",
            "          25       0.97      0.97      0.97        32\n",
            "          26       0.97      0.84      0.90        45\n",
            "          27       1.00      0.90      0.95        39\n",
            "          28       0.84      0.92      0.88        50\n",
            "          29       0.82      0.77      0.79        35\n",
            "          30       0.86      0.79      0.83        39\n",
            "          31       0.76      0.89      0.82        36\n",
            "          32       0.41      0.38      0.39        32\n",
            "          33       0.88      0.95      0.92        40\n",
            "          34       0.82      0.87      0.85        38\n",
            "          35       0.94      0.81      0.87        36\n",
            "          36       0.78      0.88      0.83        52\n",
            "          37       0.88      0.86      0.87        43\n",
            "          38       0.98      1.00      0.99        47\n",
            "          39       0.86      0.90      0.88        41\n",
            "          40       0.96      0.81      0.88        32\n",
            "          41       0.95      0.91      0.93        44\n",
            "          42       0.90      0.96      0.93        49\n",
            "          43       0.93      0.98      0.95        41\n",
            "          44       0.98      0.96      0.97        50\n",
            "          45       0.84      0.78      0.81        41\n",
            "          46       0.94      0.98      0.96        51\n",
            "          47       0.93      0.97      0.95        38\n",
            "          48       0.90      1.00      0.95        44\n",
            "          49       0.92      0.92      0.92        39\n",
            "          50       1.00      0.98      0.99        49\n",
            "          51       0.95      0.97      0.96        37\n",
            "          52       0.89      0.91      0.90        44\n",
            "          53       0.89      0.97      0.93        34\n",
            "          54       1.00      0.98      0.99        50\n",
            "          55       0.97      0.92      0.95        38\n",
            "          56       0.95      0.95      0.95        38\n",
            "          57       0.94      1.00      0.97        30\n",
            "          58       0.95      0.97      0.96        38\n",
            "          59       0.90      0.95      0.93        40\n",
            "          60       0.97      0.88      0.92        41\n",
            "          61       0.95      0.95      0.95        44\n",
            "          62       1.00      0.97      0.99        35\n",
            "          63       0.94      0.94      0.94        33\n",
            "          64       0.95      0.95      0.95        40\n",
            "          65       1.00      1.00      1.00        25\n",
            "          66       1.00      0.97      0.99        38\n",
            "          67       1.00      0.97      0.99        34\n",
            "          68       0.94      1.00      0.97        34\n",
            "          69       0.52      0.60      0.56        42\n",
            "          70       0.85      0.95      0.90        41\n",
            "          71       0.90      0.96      0.93        27\n",
            "          72       0.98      0.96      0.97        50\n",
            "          73       0.92      1.00      0.96        48\n",
            "          74       1.00      1.00      1.00        39\n",
            "\n",
            "    accuracy                           0.91      3085\n",
            "   macro avg       0.91      0.91      0.91      3085\n",
            "weighted avg       0.91      0.91      0.91      3085\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense,\n",
        "                                     Dropout, Input, BatchNormalization)\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "# 1. Enable GPU memory growth\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(f\"{len(gpus)} GPU(s) ready with memory growth.\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "\n",
        "# 2. Configuration\n",
        "img_size = (128, 128)\n",
        "data_path = '/content/data/Final DATASET'\n",
        "num_classes = 75\n",
        "\n",
        "# 3. Load Data\n",
        "X, y = [], []\n",
        "for label in range(num_classes):\n",
        "    folder_path = os.path.join(data_path, str(label))\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Missing folder: {folder_path}\")\n",
        "        continue\n",
        "\n",
        "    for file in os.listdir(folder_path):\n",
        "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
        "            img_path = os.path.join(folder_path, file)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None:\n",
        "                continue\n",
        "            img = cv2.resize(img, img_size)\n",
        "            X.append(img)\n",
        "            y.append(label)\n",
        "\n",
        "X = np.array(X).reshape(-1, img_size[0], img_size[1], 1).astype('float32') / 255.0\n",
        "y = to_categorical(np.array(y), num_classes)\n",
        "\n",
        "# 4. Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 5. Data Augmentation Function\n",
        "def augment(image, label):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
        "    image = tf.image.random_contrast(image, lower=0.9, upper=1.1)\n",
        "    return image, label\n",
        "\n",
        "# 6. tf.data Datasets\n",
        "batch_size = 64\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)) \\\n",
        "    .shuffle(buffer_size=2048) \\\n",
        "    .map(augment, num_parallel_calls=tf.data.AUTOTUNE) \\\n",
        "    .batch(batch_size) \\\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)) \\\n",
        "    .batch(batch_size) \\\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# 7. Build Model\n",
        "model = Sequential([\n",
        "    Input(shape=(img_size[0], img_size[1], 1)),\n",
        "\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# 8. Compile Model\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 9. Callbacks\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.5, patience=4, verbose=1, min_lr=1e-6)\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1)\n",
        "\n",
        "# 10. Train Model\n",
        "model.fit(train_dataset,\n",
        "          epochs=100,\n",
        "          validation_data=val_dataset,\n",
        "          callbacks=[lr_scheduler, early_stop])\n",
        "\n",
        "# 11. Evaluate\n",
        "loss, acc = model.evaluate(val_dataset)\n",
        "print(f\"\\nTest Accuracy: {acc * 100:.2f}%\")\n",
        "\n",
        "# 12. Additional Metrics\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "y_pred_probs = model.predict(X_test, batch_size=batch_size)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "precision = precision_score(y_true, y_pred, average='macro')\n",
        "recall = recall_score(y_true, y_pred, average='macro')\n",
        "f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "print(\"\\nEvaluation Metrics:\")\n",
        "print(f\"Accuracy       : {accuracy:.2f}%\")\n",
        "print(f\"Precision (avg): {precision:.4f}\")\n",
        "print(f\"Recall    (avg): {recall:.4f}\")\n",
        "print(f\"F1 Score  (avg): {f1:.4f}\")\n",
        "\n",
        "print(\"\\nDetailed Classification Report:\")\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# 13. Save Model\n",
        "model.save(\"/content/drive/MyDrive/Colab Notebooks/vattaeluthu_tamil_advanced.keras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/drive/MyDrive/Colab Notebooks/DATASET200.zip\" -d /content/data"
      ],
      "metadata": {
        "id": "B9DIRwBfqrlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86bd7774-8bb0-404b-f776-096d0ede8ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace /content/data/Final DATASET/0/image_0001.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find \"/content/data/Final DATASET\" -mindepth 1 -maxdepth 1 -type d | wc -l\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na2Joju4fAFl",
        "outputId": "6903a79d-2751-474a-c771-81291ea8690a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mrggw1_XO3CH",
        "outputId": "0cc8e177-818b-4805-8b74-7c282f2cbe37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.5-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.5-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m434.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.5\n"
          ]
        }
      ]
    }
  ]
}